from fastapi import FastAPI
from pydantic import BaseModel
from fastapi.middleware.cors import CORSMiddleware
from diffusion.generate import generate_image
from camera.show_overlay import show_image_overlay  

import threading

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class SpeechInput(BaseModel):
    text: str

@app.post("/generate")
async def generate(speech: SpeechInput):
    prompt = speech.text
    print(f"ğŸ—£ï¸ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ìˆ˜ì‹ : {prompt}")

    def run_generation():
        image_path = generate_image(prompt)
        show_image_overlay(image_path)  # ìƒì„±ëœ ì´ë¯¸ì§€ë¥¼ ì‹¤ì‹œê°„ ì˜ìƒì— ì˜¤ë²„ë ˆì´

    threading.Thread(target=run_generation).start()

    return {"status": "accepted", "message": f"í”„ë¡¬í”„íŠ¸ ìˆ˜ì‹  ì™„ë£Œ: {prompt}"}
